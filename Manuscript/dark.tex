% Preamble
\documentclass[a4paper,12pt]{article}

\usepackage[osf]{mathpazo} % palatino
\usepackage{ms}            % load the template
\usepackage[round]{natbib} % author-year citations
\usepackage{graphicx}
\usepackage{parskip}      
\pagenumbering{arabic}    

% From Syst Biol template
\linespread{1.66}

\renewcommand{\section}[1]{
  \bigskip
  \begin{center}
  \begin{Large}
  \normalfont\scshape #1
  \medskip
  \end{Large}
  \end{center}
}

\renewcommand{\subsection}[1]{
  \bigskip
  \begin{center}
  \begin{large}
  \normalfont\itshape #1
  \end{large}
  \end{center}
}

\renewcommand{\subsubsection}[1]{%
\vspace{2ex}
\noindent
\textit{#1.}---}

\renewcommand{\tableofcontents}{}

\bibpunct{(}{)}{;}{a}{}{,}  % this is a citation format command for natbib

% NC: Ignoring their title page setup as I like Rich's template better :)

% Title page information

\title{The ``Dark Side'' of Phylogenetic Comparative Methods$^\dag$}
\author{
  Richard G. FitzJohn$^{1}$, Cecile An\'{e}$^{2}$, Wayne Maddison$^{3}$,\\ Matthew W. Pennell$^{4}$, Gavin H. Thomas$^{5}$, April Wright$^{6}$,\\ and Natalie Cooper$^{7,8,*}$
}
\date{}
\affiliation{\noindent{\footnotesize
  $^1$ Department of Biological Sciences, Macquarie University, Sydney, NSW 2109, Australia. \\
  $^2$ Wisconsin\\
  $^3$ UBC\\
  $^4$ Institute for Bioinformatics and Evolutionary Studies, University of Idaho, Moscow, ID 83844, U.S.A.\\
  $^5$ Sheffield\\
  $^6$ Austin\\
  $^7$ School of Natural Sciences, Trinity College Dublin, Dublin 2, Ireland.\\ 
  $^8$ Trinity Centre for Biodiversity Research, Trinity College Dublin, Dublin 2, Ireland.\\
  $^*$ Corresponding author: ncooper@tcd.ie; Zoology Building, Trinity College Dublin, Dublin 2, Ireland. 
       Fax: +353 1 677 8094; Tel: +353 1 896 1926.\\
  $^\dag$This paper is based on a Society of Systematic Biologists symposium at Evolution 2014, in Raleigh NC.\\
}}

\vfill
%\paragraph{Word-count:} X words

\runninghead{The ``Dark Side'' of PCMs}
\keywords{PCM, assumption, etc.}

% End of preamble

\begin{document}
\modulolinenumbers[1]   % Line numbering on every line

\mstitlepage
\parindent = 1.5em
\addtolength{\parskip}{.3em}

%\section{abstract}
% NC: If Syst Biol "Point of View" there's no abstract

\newpage
\raggedright
\doublespacing
\setlength{\parindent}{1cm}

%\section{Introduction} 
% NC: No intro heading for Syst Biol

\noindent
A long time ago in a galaxy far, far away - also known as the 1980s - phylogenetic comparative methods (PCMs) were developed to deal with the statistical non-independence of species in comparative analyses (e.g. \citealp{felsenstein1985phylogenies,grafen1989phylogenetic}). 
Since then PCMs have been extended to investigate evolutionary pattern and process, and include methods for investigating drivers of diversification, the tempo and mode of trait evolution, and models of speciation and extinction (see reviews in \citealp{o2012evolutionary, pennell2013integrative}). 
PCMs have also become extremely popular over recent years; the number of papers containing the phrase `phylogenetic comparative' has increased exponentially since the 1980s (Figure \ref{PCMCitations}). 
With new methods being published almost weekly, there has never been a better time to be a comparative biologist.

\begin{figure}[h]
\centering
\includegraphics[width = 10cm]{PCMCitations.png}
\caption{PCM papers through time}
\label{PCMCitations}
\end{figure}

Unfortunately, PCMs also have a ``dark side''; they make various assumptions and suffer from biases in exactly the same way as any other statistical method \citep{freckleton2009seven,boettiger2012your}. 
The more popular these methods become, the less awareness methods-users seem to have of this dark side. Increasingly assumptions and biases are inadequately assessed in empirical studies, leading to poor model fits and misinterpreted results. 
Additionally, little consideration is given to whether using a PCM is really appropriate for the question at hand \citep{losos2011seeing}. 
To paraphrase \citet{blomberg2012independent}, the enthusiastic application of PCMs has greatly outpaced our theoretical understanding of the methods and their relations to the rest of statistical theory.\\

% NC: Do we need more explicit comments showing we're not the only people to think this, nor the first to say it?

One major issue is that two groups of people are involved with PCMs. 
At one extreme, methods-developers (``wookies'') develop new methods and implement them. They are (generally) aware of the limitations of their methods, and the assumptions that underly them. 
At the other extreme, na\"{i}ve methods-users (``ewoks'') just want to use PCMs to answer empirical questions with their data, and may not be aware of issues with the methods (of course the majority of people fall somewhere between these two extremes on the ``wookie-ewok'' spectrum; many methods-developers are developing methods with a specific empirical question in mind, while there are many advanced methods-users who have detailed knowledge of the limitations of the methods they use). 
The problem is that although methods-developers (and advanced methods-users) are aware of the problems with PCMs, this information is not being effectively transferred to methods-users. 
Additionally, the tools and approaches used to fit models are often far more user-friendly and better documented than the methods used to to assess whether that model fit is reasonable. 
Clearly more effort is needed to bridge the widening gap between methods-users and methods-developers. Here we explore the causes of this communication gap and suggest some potential solutions. % NC: still not happy with this final line or two.

\section{What impedes information transfer from methods-developers to methods-users?}
% NC: Or something similar
As scientists we mainly communicate our ideas through the literature. 
Below we propose three possible reasons for difficulties transferring information between methods-developers and methods-users via the literature.

\begin{enumerate}
\item Not everything is mentioned in the literature.
\item The literature is too technical and/or important details are hidden within the text.
\item Methods-users have bypassed the literature and gone straight to the implementation of the method.
\end{enumerate}

%Note that we assume that methods-users ignore assumptions and biases because they are unaware of them. Of course, there may be methods-users who are perfectly aware of these issues but choose to sweep them under the carpet to get their work published. Although we believe there is no excuse for doing this, we also recognize that the ``publish or perish'' culture of academia may pressurize nontenured scientists into this. Hopefully some of the changes we suggest below will also help with this problem. 
% NC: This could be left out!

\subsection{1. Not everything is mentioned in the literature}
A lot of the information needed to properly apply PCMs is not found in the literature. 
We refer to this knowledge as ``PCM folklore'' because it tends to be passed down from PIs to graduate students, and it is occasionally closer to fiction than fact.
Sometimes the folklore includes tricks to get methods working, or useful rules-of-thumb. 
Other times folklore is more opinion-based, but over time these opinions become rules. 
One example of such folklore is in the defaults of programs that perform PCMs. 
These often start out as arbitrary starting points for data exploration with no justification for their use, but over time become the way the analysis is always performed.
Useful PCM folklore is often shared among methods-developers, and among collaborating groups, but is rarely shared outside of these circles. 
When it is shared, it tends to be in the form of email exchanges between methods-developers and struggling methods-users.
This advice is extremely useful to the methods-user in question, but forms a kind of ``dark advice'' that isn't accessible to the rest of the community.\\

% NC: Do we want a specific example here? Theta estimation in OU models? 
% NC: Could mention Â±3 from Jones&Purvis97 - totally unjustified rule of thumb now = canon.
% NC: Mention hidden assumptions? I mention them later

Other information about the limitations of a method may be absent from the literature due to the time-lag between a new method being published and others having time to test and critique it. 
For example, Felsenstein published the phylogenetic independent contrasts method in 1985, but it wasn't until the early 1990s that real critiques of the method and its assumptions began to be published (e.g. \citealp{garland1992procedures})
This time-lag is shorter with more recent methods because simulations testing the method are now required by journals.
However, we suspect there are still many hidden assumptions and biases in all new PCMs that have yet to be properly explored in the literature. 
% NC: Rich, we can cite your paper on Pagel 1994 here if you like - as an example of old methods that are still being investigated.

\subsection{2. The literature is too technical and/or important details are hidden}
Although a lot of information is not found in the literature (see above), the majority of assumptions and biases of PCMs are documented somewhere. 
A big issue for novice methods-users is that this information is often extremely technical and dense.
It is not unusual for papers to be full of equations, over 20 pages long, and written in a way that gives even advanced users a headache. 
Additionally there is a lot of literature to wade through before getting all of the required information. 
For example, one of us (NC) recently reviewed papers discussing the assumptions and limitations of the most commonly used PCM, phylogenetic independent contrasts \citep{felsenstein1985phylogenies}. 
Even with prior knowledge of the key papers and authors to focus on, this resulted in XX pages, XX papers and a book to read. % NC: I will add numbers at some point!
This seems like an excessive amount of reading to expect from a methods-user trying to run a simple empirical analysis.\\

Another issue is that it can sometimes be hard to find the information required. Assumptions and caveats can be found in the Introduction, Methods, Results and/or Discussion of a paper. 
They are rarely neatly corralled in one place, making it really easy to miss pertinent details. 
This places an additional burden on methods-users who must read every paper very carefully.

\subsection{3. Users jump straight to the implementation of the method}
In the early days of PCMs, some methods-developers provided stand alone packages to run their methods, others provided code in whichever language they were comfortable programming in, and still others provided no way of implementing their methods at all. 
This resulted in many frustrating hours (and days and months!) trying to implement any new method you wanted to use.\\

More recently however, the PCM community has moved towards mostly implementing their methods in R \citep{R-Core-Team:2014aa}, and code sharing has become almost ubiquitous. 
The number of R packages for PCMs has increased exponentially since 2005 when APE \citep{Paradis:2004aa} was released, and has increased particularly sharply since 2008 (Figure \ref{PCMRpackages}).
Simultaneously, more and more methods-users are able to use R, thus when a new method is published they can now take an R package ``off the shelf'' and use it to run the method immediately.
\citet{freckleton2009seven} suggested that the ability to to conduct PCMs in flexible computing environments such as R would improve the ability of methods-users to implement methods correctly. 
However, this has instead led to an increasing number of methods-users jumping straight to the implementation of a method, without understanding what the method is doing, what its assumptions might be, or what the results mean in a biological context.
This problem is exacerbated by the fact that manuals, vignettes and help files for R packages rarely mention the assumptions of the method, or how to test model fit. 
The APE book \citep{paradis2011analysis} for example, provides no guidance on assumption testing in its chapter on phylogenetic independent contrasts, even though the methods needed to do this are well-established and very easily implemented in R (for a counter example see CAIC and caper documentation; \citep{purvis1995comparative,Orme:2013aa}.\\
We believe this issue is probably one of the biggest currently facing phylogenetic comparative biology. It is extremely frustrating reading/reviewing papers where the authors have clearly failed to carefully read or understand the primary literature on the method they are using. 
Additionally, many methods-users seem to try to retrofit a question so they can use the shiniest new methods available. This is all driven by our ``publish or perish'' culture, and the pressure to produce as many papers as possible out of a dataset.
The truly sad thing about this state of affairs is that by making science more open and sharing code (something we are all passionate about and strongly support) we seem to have made the situation worse rather than better.

\begin{figure}[h]
\centering
\includegraphics[width = 10cm]{PCMRpackages.png}
\caption{Increase in R packages through time}
\label{PCMRpackages}
\end{figure}

\section{How can we solve some of these problems?}

\subsection{1. Simplify, summarize and share}
Many of the problems above are caused by methods papers being difficult to read. 
This isn't entirely the fault of methods-developers; most journals have strict word limits so it's often easier to use a one line equation rather than a paragraph of description. 
However, it's hard to complain about novice users failing to understand a method when the paper is incomprehensible. %cough cough Hansen. Ow my eyes are bleeding.
One solution is to prepare an accompanying blog post or video explaining the method in less technical terms. 
Some journals already encourage this (e.g. Methods in Ecology and Evolution), and even if they do not, there is no harm in doing this and hosting it on a personal website. 
The ability to share ideas with a non-technical audience is a key skill to develop, and it may even encourage more people to use the method. 
% NC: Perhaps add something about having reproducible knitr reports in supp mat (e.g. cite that nice recent paper)
At the very least, having a simple list of the main assumptions, biases and caveats of the method somewhere would reduce misuse and provide a place to point methods-users to when they begin using a method.
Of course this will be difficult as there are often hidden assumptions in a method, and listing all possible assumptions and caveats may be unfeasible.\\

The glut of literature that already exists for established methods is a bigger problem. 
One solution would be to establish a wiki-style website where methods-developers and advanced methods-users could post summaries of commonly used methods, along with lists of key papers to read. 
The community would be responsible for peer reviewing these summaries to ensure all opinions are covered. 
Erick Matsen's Phylobabble discourse page (http://phylobabble.org/) is an excellent example of a similar approach for phylogenetics. Unfortunately there is currently little incentive for methods-developers and advanced methods-users to contribute to such a project at the cost of time pursuing their own research.\\

One solution is to establish a discourse page for providing R help. 
Currently most methods-users either email the R-sig-phylo help list or the package developer for assistance. 
Both approaches are suboptimal. 
R-sig-phylo is impossible to search effectively, leading to the same questions being dealt with repeatedly. 
The same is true in email exchanges between methods-users and package developers with the added issue of this being ``dark advice'' that isn't shared. 
A discourse page would collate all of this information and reduce pressure on package developers by allowing advanced methods-users to help novice users with simple queries. 
We are in the process of setting up a discourse page for this purpose (it will be called ``phyloBootstrap'' because it will provide ``support'' for PCMs). At Evolution 2014 many methods-developers agreed to move their R package help to this forum.

\subsection{2. Read, think and learn}
If methods-developers are going to put time and effort into making their methods easier to understand, then methods-users need to take advantage of this and work harder to understand the methods they are using. 
At a minimum, methods-users should read the original papers describing a method, and any recent updates. 
Jumping straight into an R implementation is a tolerable way to start a project, but it needs to be followed up by careful reading and thought. 
Methods-users also need to avoid retrofitting their question to shiny new methods, instead they should think carefully about the question they want to ask, whether the method is appropriate for the question, and whether PCMs are
needed at all \citep{losos2011seeing}.\\

Another key skill to develop is distrust; never take results from PCMs (or any other statistical analysis) at face value. 
A good way to check a method is to simulate some data and see if the results are as expected. 
This can expose hidden assumptions or biases that have not been explored in the papers accompanying the method, or reveal a lack of understanding of the the mechanics of the method being used. 
It is also important for methods-users to consider whether the method will work on their dataset; for example, how many species does it need to have reasonable power, how does it deal with polytomies, can it cope with non-ultrametric trees etc.
Finally, methods-users should never be afraid to question standard practice, sometimes it's just PCM folklore!
% NC: Could add my pglm vs pgls example.

\subsection{3. Collaboration}
A obvious solution to all these problems is for methods-developers and methods-users to collaborate more. 
The benefits to methods-users are obvious, but methods-developers can also benefit by gaining extra datasets to test their ideas on and people who will discover corner cases and bugs in their software before it get released. 
A big difficulty with collaboration is that it is often asymmetrical in terms of benefit to methods-users and methods-developers. 
Methods-developers and advanced methods-users can often put a lot of time and effort into running analyses for less experienced colleagues, yet at best they come out of the experience with a middle authored paper. 
Until these author positions are considered equal to first and last author positions, there is little incentive to collaborate extensively.

\subsection{4. Incentives}
It is important to recognize that our ability to do rigorous quantitative science often relies on highly-skilled methods-developers, especially as evolutionary biology becomes ever more computationally intensive. 
We cannot afford to lose these people to industry, nor can we afford to pay industry wages, thus we need to make it worthwhile for methods-developers to remain in (or at least interact with) academia.

First we need to stop insisting that methods papers must be entirely novel. 
Improvements to existing methods, and ways of detecting biases or testing model fit should be sufficient for publication. 
This is fairly standard in other fields, e.g. phylogenetics, and these kinds of papers are arguably more useful to the community than constantly publishing new methods.
When novel methods are published, journals should encourage methods-developers to include ways of testing the assumptions of their methods within the original publications and packages, and request simplified summaries to accompany technical papers.

Second we need to fund pure methods development, including incremental methods. 
Currently it is difficult to get funding for purely methods driven research; an empirical component is always needed and methods development is often seen as part of the bigger empirical picture, rather than the reverse. 
This unfairly prejudices funding bodies (and hiring committees) away from methods-developers. 

Finally we need to re-evaluate our criteria for success in academia. 
The ``publish or perish'' mentality does not encourage methods-developers to spend more time on their methods than necessary. 
Thus there is little incentive to summarize, simplify and share, or to collaborate with methods-users, as we suggest above. 
This mentality is also not conducive to methods-users attempting to fully understand a method prior to using it. 
Instead we need to value quality over quantity when it comes to publications.
This would improve career prospects for both methods-developers and careful methods-users.

\section{Conclusion}
% NC: Still need a couple of lines of conclusion but I'm drawing a blank. Final sentence is fine I think. We could just skip the conclusion heading and have this as a standalone sentence at the end.

Hopefully by trying to implement some of these solutions we can banish the ``Dark Side'' of PCMs and create a ``New Hope'' for the whole PCM community, whether they be wookies, ewoks or somewhere in between.

\section{Funding}
This work was supported by The European Commission CORDIS Seventh Framework Program (FP7) Marie Curie CIG grant, proposal number: 321696 (NC). 

\section{Acknowledgments}
Thanks to the Society of Systematic Biologists for funding our symposium at Evolution 2014. 
We also thank George Lucas for the ``hilarious'' Star Wars jokes.
%NC: Should possibly thank Brian O'Meara for funding discourse page

\bibliographystyle{sysbio}
\bibliography{darkside}

\end{document}
